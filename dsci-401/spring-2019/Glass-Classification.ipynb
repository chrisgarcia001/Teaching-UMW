{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Foresrt and SVM Examples Using the Glass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from error_metrics import *\n",
    "\n",
    "# Read and inspect the data.\n",
    "data = pd.read_csv('./data/glass.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get features and response/target data.\n",
    "features = list(data)\n",
    "features.remove('Type')\n",
    "data_x = data[features]\n",
    "data_y = data['Type']\n",
    "\n",
    "# Split into training and test sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ EVALUATING MODEL: n_estimators = 5, max_depth = 2 -----\n",
      "Accuracy: 0.784615384615\n",
      "Avg. F1 (Micro): 0.784615384615\n",
      "Avg. F1 (Macro): 0.626662497394\n",
      "Avg. F1 (Weighted): 0.770012026747\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.76      0.78        21\n",
      "          2       0.77      0.83      0.80        24\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.25      0.50      0.33         2\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      0.73      0.85        15\n",
      "\n",
      "avg / total       0.83      0.78      0.80        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  3  0  0  0  1]\n",
      " [ 3 20  0  1  0  2]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 1  1  0  1  0  1]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 5, max_depth = 4 -----\n",
      "Accuracy: 0.753846153846\n",
      "Avg. F1 (Micro): 0.753846153846\n",
      "Avg. F1 (Macro): 0.570454545455\n",
      "Avg. F1 (Weighted): 0.743916083916\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.75      0.75        20\n",
      "          2       0.81      0.72      0.76        29\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.50      0.50      0.50         4\n",
      "          6       0.33      1.00      0.50         1\n",
      "          7       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.78      0.75      0.76        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[15  5  0  0  0  0]\n",
      " [ 3 21  0  2  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  2  0  2  0  0]\n",
      " [ 1  0  0  0  1  1]\n",
      " [ 0  1  0  0  0 10]]\n",
      "------ EVALUATING MODEL: n_estimators = 5, max_depth = 6 -----\n",
      "Accuracy: 0.8\n",
      "Avg. F1 (Micro): 0.8\n",
      "Avg. F1 (Macro): 0.611647173489\n",
      "Avg. F1 (Weighted): 0.788722447143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.88      0.78        16\n",
      "          2       0.92      0.77      0.84        31\n",
      "          3       0.00      0.00      0.00         1\n",
      "          5       0.25      0.50      0.33         2\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.84      0.80      0.81        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[14  4  1  0  0  1]\n",
      " [ 1 24  0  1  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  2  0  1  0  1]\n",
      " [ 0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 5, max_depth = 8 -----\n",
      "Accuracy: 0.815384615385\n",
      "Avg. F1 (Micro): 0.815384615385\n",
      "Avg. F1 (Macro): 0.664686680289\n",
      "Avg. F1 (Weighted): 0.8146635765\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.90      0.86      0.88        21\n",
      "          2       0.77      0.80      0.78        25\n",
      "          3       0.00      0.00      0.00         1\n",
      "          5       0.75      0.75      0.75         4\n",
      "          6       0.67      0.67      0.67         3\n",
      "          7       0.91      0.91      0.91        11\n",
      "\n",
      "avg / total       0.82      0.82      0.82        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[18  2  0  0  0  0]\n",
      " [ 3 20  1  1  1  0]\n",
      " [ 0  1  0  0  0  0]\n",
      " [ 0  1  0  3  0  0]\n",
      " [ 0  0  0  0  2  1]\n",
      " [ 0  1  0  0  0 10]]\n",
      "------ EVALUATING MODEL: n_estimators = 10, max_depth = 2 -----\n",
      "Accuracy: 0.661538461538\n",
      "Avg. F1 (Micro): 0.661538461538\n",
      "Avg. F1 (Macro): 0.366473429952\n",
      "Avg. F1 (Weighted): 0.616258639911\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.58      0.65        26\n",
      "          2       0.65      0.68      0.67        25\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.77      0.66      0.71        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[15  5  0  0  0  0]\n",
      " [ 8 17  0  0  0  1]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 1  3  0  0  0  0]\n",
      " [ 1  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 10, max_depth = 4 -----\n",
      "Accuracy: 0.784615384615\n",
      "Avg. F1 (Micro): 0.784615384615\n",
      "Avg. F1 (Macro): 0.630982905983\n",
      "Avg. F1 (Weighted): 0.776666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80        20\n",
      "          2       0.77      0.77      0.77        26\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.50      0.50      0.50         4\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.81      0.78      0.79        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  3  0  0  0  1]\n",
      " [ 4 20  0  2  0  0]\n",
      " [ 0  1  0  0  0  0]\n",
      " [ 0  1  0  2  0  1]\n",
      " [ 0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 10, max_depth = 6 -----\n",
      "Accuracy: 0.8\n",
      "Avg. F1 (Micro): 0.8\n",
      "Avg. F1 (Macro): 0.590707950331\n",
      "Avg. F1 (Weighted): 0.787994938782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.89      0.87        19\n",
      "          2       0.81      0.78      0.79        27\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.50      0.50      0.50         4\n",
      "          6       0.33      1.00      0.50         1\n",
      "          7       1.00      0.79      0.88        14\n",
      "\n",
      "avg / total       0.84      0.80      0.81        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [ 2 21  0  2  0  1]\n",
      " [ 0  1  0  0  0  0]\n",
      " [ 0  1  0  2  0  1]\n",
      " [ 0  1  0  0  1  1]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 10, max_depth = 8 -----\n",
      "Accuracy: 0.846153846154\n",
      "Avg. F1 (Micro): 0.846153846154\n",
      "Avg. F1 (Macro): 0.685866966087\n",
      "Avg. F1 (Weighted): 0.840079141535\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.81      0.83        21\n",
      "          2       0.85      0.88      0.86        25\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.60      0.67         5\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.86      0.85      0.85        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [ 2 22  0  2  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 1  0  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 50, max_depth = 2 -----\n",
      "Accuracy: 0.769230769231\n",
      "Avg. F1 (Micro): 0.769230769231\n",
      "Avg. F1 (Macro): 0.421685498714\n",
      "Avg. F1 (Weighted): 0.719264382818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.76      0.78        21\n",
      "          2       0.88      0.72      0.79        32\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.88      0.77      0.82        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  4  0  0  0  0]\n",
      " [ 3 23  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  4  0  0  0  0]\n",
      " [ 1  1  0  0  0  1]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 50, max_depth = 4 -----\n",
      "Accuracy: 0.784615384615\n",
      "Avg. F1 (Micro): 0.784615384615\n",
      "Avg. F1 (Macro): 0.630244699506\n",
      "Avg. F1 (Weighted): 0.776696096825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.76      0.78        21\n",
      "          2       0.77      0.80      0.78        25\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.50      0.50      0.50         4\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.81      0.78      0.79        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  3  0  0  0  1]\n",
      " [ 4 20  0  2  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  1  0  2  0  1]\n",
      " [ 0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 50, max_depth = 6 -----\n",
      "Accuracy: 0.846153846154\n",
      "Avg. F1 (Micro): 0.846153846154\n",
      "Avg. F1 (Macro): 0.663361410463\n",
      "Avg. F1 (Weighted): 0.838550534069\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.89      0.87        19\n",
      "          2       0.88      0.82      0.85        28\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.50      0.50      0.50         4\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.87      0.85      0.85        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [ 1 23  0  2  0  0]\n",
      " [ 0  1  0  0  0  0]\n",
      " [ 0  1  0  2  0  1]\n",
      " [ 1  0  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ EVALUATING MODEL: n_estimators = 50, max_depth = 8 -----\n",
      "Accuracy: 0.876923076923\n",
      "Avg. F1 (Micro): 0.876923076923\n",
      "Avg. F1 (Macro): 0.730974962701\n",
      "Avg. F1 (Weighted): 0.871525851924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.94      0.89        18\n",
      "          2       0.88      0.85      0.87        27\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.60      0.67         5\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.89      0.88      0.88        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [ 1 23  0  2  0  0]\n",
      " [ 0  1  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 100, max_depth = 2 -----\n",
      "Accuracy: 0.753846153846\n",
      "Avg. F1 (Micro): 0.753846153846\n",
      "Avg. F1 (Macro): 0.416203235592\n",
      "Avg. F1 (Weighted): 0.705164501828\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.74      0.79        23\n",
      "          2       0.81      0.70      0.75        30\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.86      0.75      0.80        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [ 5 21  0  0  0  0]\n",
      " [ 0  1  0  0  0  0]\n",
      " [ 0  3  0  0  0  1]\n",
      " [ 1  2  0  0  0  0]\n",
      " [ 0  0  0  0  0 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ EVALUATING MODEL: n_estimators = 100, max_depth = 4 -----\n",
      "Accuracy: 0.815384615385\n",
      "Avg. F1 (Micro): 0.815384615385\n",
      "Avg. F1 (Macro): 0.671813452248\n",
      "Avg. F1 (Weighted): 0.809052396878\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80        20\n",
      "          2       0.81      0.81      0.81        26\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.60      0.67         5\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.83      0.82      0.82        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  4  0  0  0  0]\n",
      " [ 3 21  0  2  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ EVALUATING MODEL: n_estimators = 100, max_depth = 6 -----\n",
      "Accuracy: 0.846153846154\n",
      "Avg. F1 (Micro): 0.846153846154\n",
      "Avg. F1 (Macro): 0.692112597547\n",
      "Avg. F1 (Weighted): 0.838795986622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.85      0.85        20\n",
      "          2       0.85      0.85      0.85        26\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.50      0.50      0.50         4\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.86      0.85      0.85        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [ 2 22  0  2  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  1  0  2  0  1]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "------ EVALUATING MODEL: n_estimators = 100, max_depth = 8 -----\n",
      "Accuracy: 0.876923076923\n",
      "Avg. F1 (Micro): 0.876923076923\n",
      "Avg. F1 (Macro): 0.729933110368\n",
      "Avg. F1 (Weighted): 0.871143126662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.89      0.87        19\n",
      "          2       0.88      0.88      0.88        26\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.60      0.67         5\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.89      0.88      0.88        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [ 1 23  0  2  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  0 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Build a sequence of Random Forest models for different n_est and depth values.\n",
    "n_ests = [5, 10, 50, 100]\n",
    "depths = [2, 4, 6, 8]\n",
    "for n in n_ests:\n",
    "    for dp in depths:\n",
    "        mod = ensemble.RandomForestClassifier(n_estimators=n, max_depth=dp)\n",
    "        mod.fit(x_train, y_train)\n",
    "        y_hat = mod.predict(x_test)\n",
    "        print('------ EVALUATING MODEL: n_estimators = ' + str(n) + ', max_depth = ' + str(dp) + ' -----')\n",
    "        print_multiclass_classif_error_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Use a Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- EVALUATING MODEL: C = 0.2 ------------\n",
      "Accuracy: 0.661538461538\n",
      "Avg. F1 (Micro): 0.661538461538\n",
      "Avg. F1 (Macro): 0.376638655462\n",
      "Avg. F1 (Weighted): 0.62138332256\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.57      0.68        30\n",
      "          2       0.62      0.64      0.63        25\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.77      0.66      0.70        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  3  0  0  0  0]\n",
      " [10 16  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  4  0  0  0  0]\n",
      " [ 2  1  0  0  0  0]\n",
      " [ 0  1  0  0  0 10]]\n",
      "--------- EVALUATING MODEL: C = 0.5 ------------\n",
      "Accuracy: 0.753846153846\n",
      "Avg. F1 (Micro): 0.753846153846\n",
      "Avg. F1 (Macro): 0.478082803909\n",
      "Avg. F1 (Weighted): 0.723539797616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.70      0.74        23\n",
      "          2       0.85      0.71      0.77        31\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.25      1.00      0.40         1\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.83      0.75      0.78        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  4  0  0  0  0]\n",
      " [ 4 22  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  3  0  1  0  0]\n",
      " [ 2  1  0  0  0  0]\n",
      " [ 0  1  0  0  0 10]]\n",
      "--------- EVALUATING MODEL: C = 1.0 ------------\n",
      "Accuracy: 0.738461538462\n",
      "Avg. F1 (Micro): 0.738461538462\n",
      "Avg. F1 (Macro): 0.497359910148\n",
      "Avg. F1 (Weighted): 0.713880379354\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.64      0.71        25\n",
      "          2       0.73      0.76      0.75        25\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.50      0.67      0.57         3\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.80      0.74      0.76        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  4  0  0  0  0]\n",
      " [ 6 19  0  1  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  1  0  2  0  1]\n",
      " [ 2  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "--------- EVALUATING MODEL: C = 2.0 ------------\n",
      "Accuracy: 0.815384615385\n",
      "Avg. F1 (Micro): 0.815384615385\n",
      "Avg. F1 (Macro): 0.636199703876\n",
      "Avg. F1 (Weighted): 0.803329244437\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.76      0.78        21\n",
      "          2       0.85      0.81      0.83        27\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.75      0.75         4\n",
      "          6       0.33      1.00      0.50         1\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.85      0.82      0.83        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  4  0  0  0  0]\n",
      " [ 3 22  0  1  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 1  1  0  0  1  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "--------- EVALUATING MODEL: C = 5.0 ------------\n",
      "Accuracy: 0.846153846154\n",
      "Avg. F1 (Micro): 0.846153846154\n",
      "Avg. F1 (Macro): 0.696481068583\n",
      "Avg. F1 (Weighted): 0.838156056751\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.84      0.82        19\n",
      "          2       0.88      0.82      0.85        28\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.75      0.75         4\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.87      0.85      0.85        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  4  0  0  0  0]\n",
      " [ 2 23  0  1  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "--------- EVALUATING MODEL: C = 6.0 ------------\n",
      "Accuracy: 0.830769230769\n",
      "Avg. F1 (Micro): 0.830769230769\n",
      "Avg. F1 (Macro): 0.689451736396\n",
      "Avg. F1 (Weighted): 0.823179150628\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80        20\n",
      "          2       0.85      0.81      0.83        27\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.75      0.75         4\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.85      0.83      0.84        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[16  4  0  0  0  0]\n",
      " [ 3 22  0  1  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n",
      "--------- EVALUATING MODEL: C = 10.0 ------------\n",
      "Accuracy: 0.830769230769\n",
      "Avg. F1 (Micro): 0.830769230769\n",
      "Avg. F1 (Macro): 0.688726509951\n",
      "Avg. F1 (Weighted): 0.822410267078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.83      0.79        18\n",
      "          2       0.88      0.79      0.84        29\n",
      "          3       0.00      0.00      0.00         0\n",
      "          5       0.75      0.75      0.75         4\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.85      0.83      0.84        65\n",
      "\n",
      "Confusion Matrix: \n",
      "[[15  5  0  0  0  0]\n",
      " [ 2 23  0  1  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  1]\n",
      " [ 0  1  0  0  2  0]\n",
      " [ 0  0  0  0  0 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Make a sequence of SVM classifiers for different values of error term c. **Note: c=1.0 is default.\n",
    "cs = [0.2, 0.5, 1.0, 2.0, 5.0, 6.0, 10.0]\n",
    "for c in cs:\n",
    "    # Create model and fit\n",
    "    mod = svm.SVC(C=c)\n",
    "    mod.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_hat = mod.predict(x_test)\n",
    "    print('--------- EVALUATING MODEL: C = ' + str(c) + ' ------------')\n",
    "    print_multiclass_classif_error_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
